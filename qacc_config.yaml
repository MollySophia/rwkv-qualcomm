model:
  evaluator:
    comparator:
      enabled: true
      fetch-top: 1
      tol: 0.01
      type: l2norm
  inference-engine:
    simplify_model : False
    inference_schemas:
    - inference_schema:
        backend: cpu
        name: qnn
        precision: fp32
        tag: qnn_cpu_fp32
        target_arch: x86_64-linux-clang
    # - inference_schema:
    #     name: qnn
    #     precision: fp16
    #     target_arch: x86_64-linux-clang
    #     backend: htp
    #     tag: qnn_fp16
    #     backend_extensions:
    #       rpc_control_latency: 100
    #       vtcm_mb: 4
    #     converter_params:
    #       float_bw: 16
    #       no_simplification: True
    - inference_schema:
        backend: htp
        backend_extensions:
          rpc_control_latency: 100
          vtcm_mb: 4
        converter_params:
          algorithms: default
          param_quantizer: enhanced
          act_quantizer: tf 
          algorithms: cle
          use_per_channel_quantization: False
          use_per_row_quantization: False
          quantization_overrides: "onnx/quant_override.json"
          act_bw: 16
          bias_bw: 8
          weight_bw: 8
        name: qnn
        precision: quant
        tag: qnn_quant
        target_arch: x86_64-linux-clang
    model_path: RWKV-5-World-0.4B-v2-20231113-ctx4096.pt
  info:
    desc: Default Config
